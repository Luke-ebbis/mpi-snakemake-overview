---
title: "Reproducable bioinformatics with `Snakemake`"
subtitle: "How and why to use snakemake"
author: 
  - name: "Sibbe Bakker"
format: 
  revealjs:
    self-contained: true
    embed-resources: true
    csl:  diabetologia.csl
    slide-number: c/t
    scrollable: true
    navigation-mode: vertical
    mermaid:
      theme: neutral
    #mermaid-format: png
  beamer:
    echo: true
    fontsize: '11pt'
bibliography: "bib/BibDataBase.bib"
biblio-style: apalike
---



# Introduction

> Why reproducibility?

## Is this familiar?


::: {.columns}


::: {.column width="40%"}

::: incremental

1. You see a computational tool you want to use.

2. You spend a full day installing it.

::: {.fragment}

> How can we all solve this?

:::

:::

:::

::: {.column width="50%"}

![The reproducibility iceberg [@kimExperimentingReproducibilityBioinformatics2017]](inclusions/2024-07-03_15-13.png)

:::

:::

## Workflow languages

> There are programming languages to solve this exact problem.

- Snakemake

- CLW

- Nextflow.

- $\dots$  

## Snakemake


::: {.columns}


::: {.column width="40%"}

::: {.fragment}


Why would you use it

* Designed for bioinformatics.

* Flexible and python based.

* Easy to install.

* Large pool of examples.


:::

:::

::: {.column width="40%"}

::: {.fragment}

Why wouldn't you use it

* You do not need to make a workflow

* If your dependencies can't be installed using conda.

* If your programme needs to be used by non experts.

:::

:::


:::

## What is a snakemake workflow?

::: incremental

::: {.fragment}

![](inclusions/snakemake-overview.png)

:::

::: fragment

```python
## sha
rule sha:
  input: "data/{filename}.{ex}"
  output: "results/{filename}.{ex}.sha"
  shell: "sha1sum  {input} | cut -d ' ' -f 1 > {output}"
```

:::

::: fragment

```bash
snakemake results/test.txt.sha
# --> Snakemake does: 
# sha1sum data/test.txt | cut -d ' ' -f 1 > results/test.txt.sha

```

:::


:::

## Getting started$\dots$


Get Snakemake with the following commands^[From the [Documentation](https://snakemake.readthedocs.io/en/stable/getting_started/installation.html)]

```bash
# Global instalation, assuming a bashlike environment...
conda install -n base -c conda-forge mamba
mamba create -c conda-forge--c bioconda -n snakemakes snakemake
mamba activate snakemake
```


> Lets get started with an example problem...

::: notes

Windows/mac operating system is supported. Project specific version is possible (more at the end).

:::


# Read mapping with Snakemake

> Two strains in an evolution experiment.

<br>

::: aside
Tutorial adapted from `https://genomics.sschmeier.com/`
:::

## Experimental work

> We have a culture of Ancestor bacteria, we apply an evolution experiment to two cultures.

![](inclusions/workflow.png)

## Initialisation

::: incremental


::: {.columns}

::: {.column width="40%"}

::: fragment
* We work on a git repository.
:::

::: fragment
* We work with a set file structure.
:::

::: fragment
* We specificy dependencies via conda.
:::



:::

::: {.column width="60%"}

::: fragment
```bash
$ git init snakemake-example
$ mkdir -p workflow/envs workflow/scripts
$ touch workflow/Snakefile
$ mkdir data results
$ tree
├── LICENSE
├── README.md
|── results/
|── data/
└── workflow/
    ├── envs/
    |── scripts/
    └── Snakefile

```
:::
:::
:::

:::


## First rule: QC (i)


```bash
$ cd data
$ wget https://osf.io/2jc4a/download -O download.tar.gz
$ tar -xzf download.tar.gz
$ ls data
anc_R1.fastq.gz  anc_R2.fastq.gz  evol1_R1.fastq.gz
evol1_R2.fastq.gz  evol2_R1.fastq.gz  evol2_R2.fastq.gz
```

Now quality control:

* We need `fastqc` and `multiqc`.

* How?

* From [`prefix.dev`](https://prefix.dev/channels/bioconda/packages/fastqc).


## First rule: QC (ii)

```bash
$ touch workflow/envs/qc.yml
$ open workflow/envs/qc.yml
```

Then add the following contents $\dots$

```yaml
name: quality-control
channels:
  - conda-forge
  - bioconda
dependencies:
  - fastqc # quality scoring
  - multiqc # for reporting
  - fastp # Trimming reads
```
From now we need to run with the `--use-conda` parameter.

## First rule: QC (iii)

Now we type the rule$\dots$

```
$ open workflow/Snakefile
```

Let's try $\dots$

```
rule fastqc:
  conda: "envs/qc.yml"
  input: "data/data/{seqname}.fastq.gz"
  output: directory("results/quality-control")
  shell: "mkdir {output}; fastqc {input} -o {output}"
```

```
$ snakemake results/quality-control
WildcardError in rule fastqc in filesnakemake-tutorial/snakemake-tutorial/workflow/Snakefile, line 18:
Wildcards in input files cannot be determined from output files: (rule fastqc, line 25, snakemake-tutorial/snakemake-tutorial/workflow/Snakefile)
'seqname'
```


## First rule: QC (iv)

* That did not work


```python
rule fastqc:
  conda: "envs/qc.yml"
  input: expand("data/data/{seqname}.fastq.gz", 
      seqname=glob_wildcards("data/data/{seqname}.fastq.gz").seqname)
  output: directory("results/quality-control/fastqc")
  shell: "mkdir {output}; fastqc {input} -o {output}"
```

* This does!

```bash
$ tree results
results/
└── quality-control
    ├── anc_R1_fastqc.html
    ├── evol1_R1_fastqc.html
    ...
    ├── evol2_R2_fastqc.html
    └── evol2_R2_fastqc.zip
```

## Intermission: why didn't that work?

::: incremental

> Wildcards are determined from the _output_!

::: {.fragment}

![The Directed acyclic graph [@SnakemakeBioinformaticsHow].](inclusions/dag.svg){width="80%"}
:::


:::

## First rule: QC (v)


```python
rule multiqc:
  conda: "envs/qc.yml"
  input: rules.fastqc.output
  output: directory("results/quality-control/multiqc")
  shell: "multiqc {input} -o {output}"
```
![Multiqc output](inclusions/multiqc.png)

# Sharing your workflow

> So now we have snakemake, conda and possibly other dependencies not yet handled $\dots$.

# Advanced usage

_see the [documentation](https://snakemake.readthedocs.io/en/stable/) for more information_

## Usefull commands.


`killall -TERM snakemake`
:   Stops the submission of new tasks and kills snakemake when tasks have finished.

::: aside

Taken from the [FAQ](https://snakemake.readthedocs.io/en/v7.0.3/project_info/faq.html#id43)

:::

# Further information

## What I based my presentation on

* [Reproducible Data Analytic Workflows for Economics](https://lachlandeer.github.io/snakemake-econ-r-tutorial/project-organization.html)

## Repositories

* This presentation: <br>  `https://github.com/Luke-ebbis/mpi-snakemake-overview`.

* The tutorial for readmapping: <br> `https://github.com/Luke-ebbis/snakemake-tutorial`.

* Example workflow for the raven cluster: <br>  `https://github.com/Luke-ebbis/snakemake-pixi`.

## Cited works

